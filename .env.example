# Cloud budget guard
CLOUD_BUDGET_USD=400
# Set your GPU hourly rate (e.g., 1x A100 ~ $1.10–$2.10/hr depending on provider)
GPU_HOURLY_USD=
# Optional budget to cap API spend
API_BUDGET_USD=0

# Default local HF models (semicolon-separated)
MODELS=meta-llama/Llama-3.1-8B-Instruct; mistralai/Mistral-7B-Instruct-v0.3; Qwen/Qwen2.5-7B-Instruct

# Optional API model for Inspect providers (off by default)
INSPECT_EVAL_MODEL=

# Runtime
DEVICE=cuda
DTYPE=bfloat16
BATCH_SIZE=4
MAX_SEQ_LEN=4096
SEEDS=123;456
 # Enable HF cloze smoke test in CI/tests (0=skip by default)
 RUN_HF_CLOZE_SMOKE=0

# Paths
LOGS_DIR=logs
RESULTS_DIR=artifacts/results
FIGS_DIR=artifacts/figs
BUDGET_DIR=.budget

# Hugging Face cache (set to a fast disk with enough space)
# Expect ~15–20 GB per 7B–8B model in cache (weights+tokenizer)
#HF_HOME=/mnt/ssd/.cache/huggingface
#TRANSFORMERS_CACHE=/mnt/ssd/.cache/huggingface/hub

# Consensus threshold for choices-only exploitable (majority voting)
CONSENSUS_K=2
