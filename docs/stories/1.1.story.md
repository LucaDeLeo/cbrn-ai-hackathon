# Story 1.1: Project Setup & Data Pipeline

## Status
Done

## Story
**As a** developer,
**I want** a clean project structure with data loading capabilities,
**so that** the team can start parallel development immediately.

## Acceptance Criteria
1. Repository initialized with structure: `src/`, `tests/`, `configs/`, `data/`, `cache/`, `results/`
2. Minimal requirements.txt with only: torch, transformers, numpy, tqdm (installed via `uv pip install`)
3. Data loader handles both JSONL and CSV formats with consistent internal representation
4. Configuration system using Python dataclasses (no external deps) with JSON serialization (stdlib-only)
5. Hash-based question ID generation working with configurable salt
6. Basic logging setup writing to both console and file
7. Successfully loads and parses WMDP-Bio sample (first 100 questions) from `data/wmdp_bio_sample_100.jsonl`
8. Determinism controls set and documented: fixed Python/NumPy/Torch seeds; `torch.use_deterministic_algorithms(True)`; cuDNN deterministic enabled and benchmarking disabled; sorted iteration order

## Tasks / Subtasks
- [x] Task 1: Initialize project structure (AC: 1)
  - [x] Create directory structure: src/, tests/, configs/, data/, cache/, results/, logs/
  - [x] Initialize Python packages with __init__.py files
  - [x] Create main CLI entry point at cli.py
- [x] Task 2: Setup dependencies and environment (AC: 2)
  - [x] Create requirements.txt with minimal dependencies: torch>=2.0, transformers>=4.36, numpy>=1.24, tqdm>=4.66
  - [x] Create scripts/setup.sh for environment setup with uv commands
  - [x] Create scripts/validate_install.py for installation verification
- [x] Task 3: Implement configuration system (AC: 4)
  - [x] Create src/config.py with dataclasses for configuration
  - [x] Implement JSON serialization/deserialization using built-in libraries
  - [x] Create default configuration at configs/default.json
- [x] Task 4: Implement data loading system (AC: 3, 5, 7)
  - [x] Create src/data/loader.py with support for JSONL and CSV formats
  - [x] Create src/data/schemas.py with data models/dataclasses
  - [x] Create src/data/validators.py for input validation
  - [x] Implement hash-based ID generation in src/security/anonymizer.py
  - [x] Test with WMDP-Bio sample (first 100 questions) from `data/wmdp_bio_sample_100.jsonl`
- [x] Task 5: Setup logging infrastructure (AC: 6)
  - [x] Create src/utils/logging.py with dual console/file logging
  - [x] Configure structured logging using built-in logging module
  - [x] Ensure logs directory is created and logs are written correctly
- [x] Task 6: Implement determinism controls (AC: 8)
  - [x] Set all random seeds in pipeline initialization
  - [x] Configure PyTorch deterministic algorithms
  - [x] Set environment variables for CUDNN and CUBLAS determinism
  - [x] Document all settings in code comments
- [x] Task 7: Create initial tests (Testing requirements)
  - [x] Create test fixtures at tests/fixtures/sample_questions.json
  - [x] Create tests/test_pipeline.py for basic integration test
  - [x] Verify deterministic behavior across runs

## Dev Notes

### Project Structure
The project follows the structure defined in [Source: architecture/project-structure.md]:
- Main entry point: `cli.py` at project root
- Core code in `src/` directory with submodules for data, analysis, models, cache, security, reporting, and utils
- Tests in `tests/` directory with fixtures in `tests/fixtures/`
- Configuration files in `configs/` directory
- Output directories: `results/`, `cache/`, `logs/`

### Tech Stack Requirements
From [Source: architecture/tech-stack.md#Core Dependencies]:
- Python 3.10+ as primary language
- PyTorch 2.0+ for model inference
- Transformers 4.36+ for model loading
- NumPy 1.24+ for numerical computations
- tqdm 4.66+ for progress bars
- Built-in libraries only for: SQLite3, json/csv parsing, argparse CLI, dataclasses config, unittest testing, logging, concurrent.futures, hashlib

### Data Components
Create these modules in `src/data/` [Source: architecture/project-structure.md#data]:
- `loader.py`: Dataset loading logic for JSONL and CSV formats
- `schemas.py`: Data models using Python dataclasses
- `validators.py`: Input validation logic

### Security Components
Create `src/security/anonymizer.py` [Source: architecture/project-structure.md#security] for hash-based ID generation using hashlib with configurable salt.

### Configuration System
Use Python dataclasses in `src/config.py` [Source: architecture/tech-stack.md#Core Dependencies] with no external dependencies. JSON serialization/deserialization using standard library (`json`). Default config file: `configs/default.json`.

### Internal Representation
From PRD FR6 [Source: prd.md#Requirements → Functional]:
- JSON fields: `question` (str), `choices` (List[str]), `answer` (int or letter)
- Internal dataclass should at minimum include: `id: str`, `question: str`, `choices: List[str]`, `answer: int` (0-based), and optional metadata fields as needed (e.g., `topic`, `difficulty`).

CSV inputs must map deterministically to the same internal schema as JSONL. Define and validate the CSV→internal field mapping in `src/data/validators.py` and/or configuration.

### Determinism Requirements
From [Source: architecture/determinism-controls.md]:
- Set seeds: `random.seed(SEED)`, `np.random.seed(SEED)`, `torch.manual_seed(SEED)`, `torch.cuda.manual_seed_all(SEED)`
- PyTorch: `torch.use_deterministic_algorithms(True)` (PyTorch 2.x)
- cuDNN: Set environment variables `CUDNN_DETERMINISTIC=1`, `CUDNN_BENCHMARK=0`
- cuBLAS: Set `CUBLAS_WORKSPACE_CONFIG=:4096:8` (or `:16:8`)
- Python hashing: Set `PYTHONHASHSEED=0`
- Tokenizers: Set `TOKENIZERS_PARALLELISM=false`
- Ensure stable iteration order by sorting data structures

### Logging Setup
Create `src/utils/logging.py` [Source: architecture/project-structure.md#utils] using built-in logging module [Source: architecture/tech-stack.md#Core Dependencies].

### Testing
From [Source: architecture/testing-strategy.md]:
- Test organization follows testing pyramid with 70% unit tests
- Create test fixtures in `tests/fixtures/` directory
- Use built-in unittest framework [Source: architecture/tech-stack.md#Core Dependencies]
- Ensure determinism validation test is included

Initial test scenarios for this story:
- JSONL and CSV loaders produce identical internal objects for the same records (schema parity check).
- Determinism: with fixed seeds and env vars (per Determinism Requirements), two runs produce bit-for-bit equal outputs for IDs and ordering.
- Hash-based ID generation: stable for same input+salt; changes when salt changes; no collisions on small sample set.
- Logging: validates a log file is created in `logs/` and console handler is active.

### Data Flow Context
From [Source: architecture/data-flow-architecture.md]:
- DataLoader is the first component in the processing pipeline
- Must integrate with CacheManager for checkpoint support
- Orchestrator will call load_dataset(path) method

### Output Schemas
The data loader should prepare for these output formats [Source: architecture/output-schemas.md]:
- Robust subset as JSONL with hashed IDs
- JSON format for reports
- JSONL format for audit logs

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-09-12 | 1.0 | Initial story creation | Bob (Scrum Master) |
| 2025-09-13 | 1.1 | Implemented Story 1.1; scaffolding, loaders, tests, CLI | James (Dev) |

## Dev Agent Record

### Agent Model Used
OpenAI Assistant (Codex CLI), persona: James (dev)

### Debug Log References
- Local test run logs: `logs/test.log`

### Completion Notes List
- Implemented minimal, stdlib-based config, logging, determinism utilities
- Data loader supports JSONL/CSV with validated schema parity and stable IDs
- Determinism controls guard optional torch import; environment-safe without deps
- Tests verify WMDP sample load (100 items), parity, IDs, logging, env flags
- CLI `load` command wires config + logging + determinism + loader

### File List
- requirements.txt
- cli.py
- configs/default.json
- src/__init__.py
- src/config.py
- src/data/__init__.py
- src/data/schemas.py
- src/data/validators.py
- src/data/loader.py
- src/security/__init__.py
- src/security/anonymizer.py
- src/utils/__init__.py
- src/utils/logging.py
- src/utils/determinism.py
- scripts/setup.sh
- scripts/validate_install.py
- tests/__init__.py
- tests/fixtures/sample_questions.json
- tests/fixtures/sample_questions.csv
- tests/test_pipeline.py
- cache/.gitkeep
- results/.gitkeep
- logs/.gitkeep

## QA Results
### Review Date: 2025-09-13T00:00:00Z

### Reviewed By: Quinn (Test Architect)

### Code Quality Assessment

The implementation satisfies the story’s functional scope with a clean, minimal dependency footprint and clear module boundaries. Configuration uses stdlib dataclasses with JSON serialization; determinism controls are applied comprehensively with safe fallback when Torch is unavailable; logging provides dual console/file handlers with a consistent formatter. Data loading covers JSONL and CSV with normalization and stable hash IDs (BLAKE2b) using an optional salt. Test coverage is pragmatic and verifies key ACs (loader parity, determinism env flags, anonymizer stability, logging output, sample load of 100 records). Overall readability and maintainability are good for a foundational story.

### Refactoring Performed

None – no changes required during QA. Code is clear and aligned with scope.

### Compliance Check

- Coding Standards: ✓ No style or structural violations observed for this scope
- Project Structure: ✓ Matches expected directories and file placement
- Testing Strategy: ✓ Unit/integration mix appropriate for early pipeline
- All ACs Met: ✓ Evidence in code and tests (see traceability)

### Requirements Traceability (AC → Evidence)

- AC1 (Repo structure): Implemented; validated by file layout and File List
- AC2 (Minimal requirements): Verified in `requirements.txt`
- AC3 (JSONL/CSV parity): Tested in `tests/test_pipeline.py::test_json_csv_parity`
- AC4 (Dataclass config + JSON I/O): Implemented in `src/config.py` (no direct test yet)
- AC5 (Hash-based IDs with salt): Implemented in `src/security/anonymizer.py`; used in loader; stability tested
- AC6 (Logging console+file): Tested in `tests/test_pipeline.py::test_logging_outputs`
- AC7 (Load WMDP-Bio 100): Tested in `tests/test_pipeline.py::test_jsonl_load_sample`
- AC8 (Determinism controls): Implemented in `src/utils/determinism.py`; env flags tested

Trace summary:
- AC covered by tests: [2, 3, 5, 6, 7, 8]
- AC implemented but not directly tested: [1, 4]

### Improvements Checklist

- [ ] Add unit tests for `AppConfig.to_json/from_json` round‑trip and defaults
- [ ] Add a small CLI invocation test for `load` happy path (smoke)
- [ ] Document CSV mapping heuristics for non-standard schemas (README snippet)
- [ ] Consider exposing `id_salt` via CLI flag override for convenience

### Security Review

No sensitive data stored; IDs are hashed deterministically (BLAKE2b, 16‑byte digest). No external I/O beyond reading datasets and writing logs. No immediate security concerns for this scope.

### Performance Considerations

Data sizes here are small; loader is streaming JSONL/CSV and constructs lightweight dataclasses. Deterministic sorting by `(id, question)` is acceptable for expected sizes; can be revisited for very large datasets.

### Files Modified During Review

None

### Gate Status

Gate: PASS → docs/qa/gates/1.1-project-setup-and-data-pipeline.yml
Risk profile: (not generated)
NFR assessment: (not generated)

### Recommended Status

✓ Ready for Done

### Review Date: 2025-09-13T00:30:00Z

### Reviewed By: Quinn (Test Architect)

### Code Quality Assessment

Follow-up recommendations implemented: added config round‑trip tests, CLI smoke test, `--id-salt` override, and CSV mapping docs. No regressions introduced; scope remains tight and maintainable.

### Refactoring Performed

- File: `cli.py`
  - Change: Added `--id-salt` flag and wiring to `load_dataset`
  - Why: Improves operability; enables runtime ID control without editing config
  - How: argparse option forwarded to loader, overriding config when provided

### Compliance Check

- Coding Standards: ✓
- Project Structure: ✓
- Testing Strategy: ✓ New tests cover config I/O and CLI smoke path
- All ACs Met: ✓

### Improvements Checklist

- [x] Add unit tests for AppConfig round‑trip and defaults
- [x] Add CLI `load` smoke test
- [x] Document CSV mapping heuristics in README
- [x] Expose `id_salt` via CLI override

### Security Review

No new security surface; CLI option affects only hashing salt in-memory.

### Performance Considerations

No impact; minor CLI argument parsing.

### Files Modified During Review

- `cli.py`
- `tests/test_config.py`
- `tests/test_cli_smoke.py`
- `README.md` (CSV mapping heuristics)

### Gate Status

Gate: PASS (unchanged) → docs/qa/gates/1.1-project-setup-and-data-pipeline.yml
Risk profile: (not generated)
NFR assessment: (not generated)

### Recommended Status

✓ Ready for Done
