# Story 1.4: Schema Validation & Stratified Sampling

## Status
Draft

## Story
**As a** developer,
**I want** strict schema validation and a stratified sampler,
**so that** data quality issues are caught early and analyses preserve topic balance.

## Acceptance Criteria
1. Schema validation with clear errors for missing fields or invalid types
2. Dataset hash and row count logged for audit
3. Stratified sampler supports topic/difficulty strata with fixed seeds
4. CLI `--subset` can sample stratified subsets deterministically
5. Summary of per-stratum counts in reports (no plaintext content)

## Tasks / Subtasks
- [ ] Enhance schema validation in `src/data/validators.py` (AC: 1)
  - [ ] Create `validate_schema()` function with comprehensive type checking
  - [ ] Check required fields: question (str), choices (list[str] min 2), answer (valid index)
  - [ ] Check optional fields: topic (str), difficulty (str/int)
  - [ ] Validate choices are non-empty strings
  - [ ] Return detailed error messages with field name and validation issue
  - [ ] Add validation for duplicate choices detection
  - [ ] Integration point: Invoke `validate_schema(obj)` inside `load_dataset()` immediately after mapping/record creation (replace/augment current `validate_record()`), ensuring exceptions propagate with clear, user-facing messages
- [ ] Create dataset auditing functionality in `src/data/loader.py` (AC: 2)
  - [ ] Compute dataset hash using hashlib over sorted question IDs
  - [ ] Count total questions and per-field statistics
  - [ ] Log dataset metadata: path, format, hash, row count, timestamp
  - [ ] Store audit info in returned dataset metadata for downstream use
  - [ ] Do not change `load_dataset()` return type; instead add `compute_dataset_audit(questions, dataset_path, fmt) -> Dict[str, Any]` helper returning `{hash, row_count, path, format, timestamp}` for downstream use
- [ ] Implement stratified sampler in new `src/data/sampler.py` (AC: 3)
  - [ ] Create `StratifiedSampler` class with configurable strata fields
  - [ ] Implement `sample(questions, n, strata_field, seed)` method
  - [ ] Support stratification by topic, difficulty, or custom field
  - [ ] Maintain proportional representation across strata
  - [ ] Handle edge cases: empty strata, insufficient samples per stratum
  - [ ] Use numpy.random.RandomState(seed) for deterministic sampling
- [ ] Integrate sampler with CLI in `cli.py` analyze command (AC: 4)
  - [ ] Add `--subset` flag accepting integer or percentage (e.g., 100, 0.1, 10%)
  - [ ] Add `--stratify-by` flag with choices=['topic', 'difficulty', 'none']
  - [ ] Add `--sampling-seed` flag (integer, default from config)
  - [ ] Apply sampling after dataset loading, before analysis
  - [ ] Log sampling parameters and resulting dataset size
  - [ ] After loading, call `compute_dataset_audit(...)` and pass `dataset_hash` to `analyze_questions(..., dataset_hash=...)`; log `row_count` and `hash` to console and file
- [ ] Add stratum summary to report generation (AC: 5)
  - [ ] Create `get_stratum_summary(questions, field)` helper function
  - [ ] Count questions per stratum value (no content exposure)
  - [ ] Include summary in HeuristicReport metadata
  - [ ] Format as: {"topic_distribution": {"biology": 45, "chemistry": 32, ...}}
  - [ ] Ensure no plaintext question/answer content in summaries
- [ ] Write comprehensive tests in `tests/test_validation_sampling.py` (AC: 1-5)
  - [ ] Test schema validation with valid/invalid inputs
  - [ ] Test dataset hash computation and stability
  - [ ] Test stratified sampling preserves proportions
  - [ ] Test CLI integration with subset flags
  - [ ] Test stratum summary generation
  - [ ] Mock file I/O and use synthetic test data

## Dev Notes

### Previous Story Insights
From Story 1.3 implementation (Status: Done):
- CLI uses argparse subparsers with "load" and "analyze" commands
- Analyze command integrates with `analyze_questions()` from heuristics module
- Error handling patterns established with structured logging
- Test patterns use unittest with mocking for file I/O
- CLI validates input files and handles errors gracefully
[Source: Story 1.3 Dev Agent Record]

### Source Tree Placement
- Validation enhancement: `src/data/validators.py` (existing file)
- New sampler module: `src/data/sampler.py` (new file)
- Data loader enhancement: `src/data/loader.py` (existing file)
- CLI integration: `cli.py` (existing file, analyze command)
- Test file: `tests/test_validation_sampling.py` (new file)
[Source: architecture/project-structure.md]

### Tech Stack Constraints
- Random sampling: NumPy's RandomState for determinism (already in requirements.txt)
- Hashing: hashlib (built-in) for dataset fingerprinting
- No additional dependencies should be added
- Use dataclasses for configuration (stdlib only)
[Source: architecture/tech-stack.md]

### Existing Data Infrastructure
Current implementation in `src/data/`:
- `validators.py`: Has `validate_record()`, `normalize_answer()`, `apply_csv_mapping()`
- `loader.py`: Has `load_dataset()` returning List[Question]
- `schemas.py`: Defines Question dataclass with id, choices, answer, topic, difficulty, metadata
- Question IDs generated via `make_question_id()` using BLAKE2b hash
The new validation and sampling features should integrate with these existing components.
[Source: Direct code inspection]

### Data Flow Integration
- Input: Dataset path → `load_dataset()` → List[Question]
- **NEW**: Questions → `validate_schema()` → Validated Questions
- **NEW**: Questions → `StratifiedSampler.sample()` → Subset[Questions]
- Processing: Questions → `analyze_questions()` → HeuristicReport
- Report includes dataset metadata and stratum summaries
[Source: architecture/data-flow-architecture.md#processing-pipeline-stages]

### Component Architecture Guidelines
From Data Loader Module specification:
- `validate_schema(data: Dict) -> bool` interface defined
- Schema validation should be comprehensive with clear error messages
- Dataset processing must maintain deterministic order
- All validation errors should be fail-fast with descriptive messages
[Source: architecture/component-architecture.md#1-data-loader-module]

### Fail-Graceful Patterns
- Validation failures should provide clear, actionable error messages
- Log all validation issues with field names and specific problems
- Sampling should handle edge cases gracefully (empty strata, insufficient samples)
- If stratification fails, fall back to simple random sampling with warning
[Source: architecture/fail-graceful-architecture-patterns.md]

### Testing Standards
- Framework: unittest (per tech stack)
- Test location: `tests/test_validation_sampling.py`
- Use mocking for file I/O to avoid dependencies
- Test edge cases: empty datasets, single-item strata, invalid schemas
- Test determinism: same seed produces same sample
- Follow patterns from existing tests
[Source: architecture/testing-strategy.md]

### Security Considerations
- No plaintext question/answer content in logs or reports
- Use hashed IDs for all external references
- Stratum summaries show only counts, not content
- Dataset hash provides integrity checking without exposing content
[Source: architecture/security-design.md#hash-based-anonymization-system]

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-09-13 | 1.0 | Initial story draft created | Bob (Scrum Master) |

## Dev Agent Record

### Agent Model Used
(To be populated by Dev Agent)

### Debug Log References
(To be populated by Dev Agent)

### Completion Notes List
(To be populated by Dev Agent)

### File List
(To be populated by Dev Agent)

## QA Results
(To be populated by QA Agent)
