**A post from Mary Ellen Callahan, Assistant Secretary, DHS Countering Weapons of Mass Destruction Office (CWMD)**

Advances in Artificial Intelligence create great promise while also posing unique threats in the Chemical, Biological, Radiological, and Nuclear (CBRN) space. Today, we are releasing a [first-of-its-kind federal government report](https://www.dhs.gov/publication/fact-sheet-dhs-advances-efforts-reduce-risks-intersection-artificial-intelligence-and) evaluating the potential for AI to be misused to enable the development or production of Chemical, Biological, Radiological, and Nuclear (CBRN) threats, while also considering the benefits and application of AI to counter them.

We found that, at this time, barriers to deploying a weapon of mass destruction remain significant, particularly for the physical creation of a CBRN threat. But increased public access to AI tools, when combined with known inconsistencies in U.S. biological and chemical security regulations, are lowering those barriers. To manage this risk and prevent AI from further lowering these barriers or creating new CBRN threats in the future, we must work rapidly. Greater cross-sector collaboration — by governments, the private sector, and academia – is needed to ensure guardrails remain strong as AI technology evolves.

Developed by DHS CWMD through extensive consultation with experts in and outside of government, the report reflects the type of coordination necessary to realizing the promise and mitigating the threat of this technology. Through [Voluntary Commitments](https://www.whitehouse.gov/briefing-room/statements-releases/2023/07/21/fact-sheet-biden-harris-administration-secures-voluntary-commitments-from-leading-artificial-intelligence-companies-to-manage-the-risks-posed-by-ai/) in 2023, Frontier AI Developers are already moving toward safe, secure, and transparent development of AI technology. However, more work is necessary, and the report provides several recommendations to ensure the continued security of the American people, including:

-   **Sharing Expertise:** Developers of the most powerful, cutting-edge AI systems – known as AI frontier models – have implemented structured testing efforts to find flaws and vulnerabilities in AI systems as part of their Voluntary Commitments, but each company has a different approach to testing. These varied approaches, coupled with inconsistent access to relevant CBRN expertise, make it vital that industry, government, and academia continue to collaborate and share their CBRN knowledge in order to increase CBRN safety and security standards in AI Models. The report mentions the DHS Artificial Intelligence Safety and Security Board as one mechanism to promote information sharing and establish best practices and risk mitigation strategies.
-   **Enhanced Protections of Sensitive Chemical and Biological Data:** Developers should use heightened standards for accessing particularly high-risk specialized tools and services, such as tools for designing or developing biological materials or chemicals. These concepts could take advantage of well-established implementation models like the Cybersecurity and Infrastructure Security Agency’s “Secure by Design” initiative and could be applied to U.S. government grant awardees via funding agency terms.
-   **Training and Education:** Developers should implement a CBRN threat awareness training for model evaluators or teams testing AI vulnerabilities to improve the security involved in model development. The government, international allies, and other security experts could provide expertise to support such training.

The responsible use of AI holds great promise for advancing science, analyzing large data sets, solving pressing challenges, and improving national security. We want to amplify the promise of AI in chemical and biological discoveries while reducing the peril of novel CBRN threats. CWMD is already integrating AI and machine learning technologies into our work, including radiological detection at the border and national biosurveillance. While government agencies have already started applying AI to certain fields like cargo and passenger screening, other fertile areas for further research include how to integrate AI into CBRN prevention and detection efforts like international arms control and monitoring efforts.

President Biden recognized the importance of this work in his October 2023 Executive Order 14110 “Safe, Secure and Trustworthy Development and Use of Artificial Intelligence,” which directed DHS to produce this report. CWMD demonstrated its enduring value by taking on this challenge and delivering the report as a centerpiece of the AI E.O. six-month requirements. My vision for CWMD for 2024 is PREPARE-CONNECT-TRANSFORM and this report is an exemplar of each of these three areas. CWMD remains committed to ensuring the safety of the Americans from CBRN threats, and through a whole-of-community approach realizing the promise and mitigating the threat posed by AI in this space.
